- en: Reactive Microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll implement reactive microservices using Spring Boot, Spring
    Stream, Apache Kafka, and Apache Avro. We'll make use of the existing Booking
    microservice to implement the message producer, or in other words, generate the
    event. We'll also create a new microservice (Billing) for consuming the messages
    produced by the updated Booking microservice, or we can say, for consuming the
    event generated by the Booking microservice. We'll also discuss the tradeoffs
    between REST-based microservice and event-based microservice.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of the reactive microservice architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Producing an event
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consuming the event
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of the reactive microservice architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, the microservices we have developed are based on REST. We have used
    REST for both internal (inter-microservice, where one microservice communicates
    with another microservice in the same system) and external (through the public
    API) communication. At present, REST fits best for the public API. Are there other
    alternatives for inter-microservices communication? Is it the best approach to
    implement the REST for inter-microservices communication? We'll discuss all this
    in this section.
  prefs: []
  type: TYPE_NORMAL
- en: You can build microservices that are purely asynchronous. You can build microservice-based
    systems that would communicate based on events. There is a tradeoff between REST
    and event-based microservices. REST provides synchronous communication, whereas
    reactive microservices are based on asynchronous communication (asynchronous message
    passing).
  prefs: []
  type: TYPE_NORMAL
- en: We can use asynchronous communication for inter-microservice communication.
    Based on the requirement and functionality, we can choose REST or asynchronous
    message passing. Consider the example case of a user placing an order, which makes
    a very good case for implementing reactive microservices. On successful order
    placement, the inventory service would recalculate the available items; account
    service would maintain the transaction, correspondence service would send the
    messages (SMS, emails, and so on) to all involved users such as a customer and
    a supplier. In this case, more than one microservice may perform distinct operations
    (inventory, accounts, messaging, and so on) based on an operation (order placement)
    performed in one microservice. Now, just think if all these communications were
    synchronous. Instead, reactive communication, with asynchronous message passing,
    provides efficient use of hardware resources, non-blocking, low latency, and high
    throughput operations.
  prefs: []
  type: TYPE_NORMAL
- en: We can primarily divide the microservice implementations into two groups—REST-based
    microservices and event-based/message-driven microservices. Reactive microservices
    are event-based.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/42dd3919-b165-4b8a-b0d2-ec2cf4aacd8b.png)'
  prefs: []
  type: TYPE_IMG
- en: Reactive manifesto
  prefs: []
  type: TYPE_NORMAL
- en: Reactive microservices are based on the Reactive Manifesto ([https://www.reactivemanifesto.org/](https://www.reactivemanifesto.org/)).
    The Reactive Manifesto comprises of four principles, which we will now discuss.
  prefs: []
  type: TYPE_NORMAL
- en: Responsive
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Responsiveness is the characteristic of serving a request in a timely manner.
    It is measured by the latency. The producer should provide the response in time
    and the consumer should receive the response in time. A failure in the chain of
    operations performed for a request should not cause a delay in response or failure.
    Therefore, it is very important for availability of services.
  prefs: []
  type: TYPE_NORMAL
- en: Resilient
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A resilient system is a robust system. The resilient principle is in line with
    the responsive principle. A microservice, despite failures, should provide the
    response, and if one instance of the microservice gets down, the request should
    be served by another node of the same microservice. A resilient microservice system
    is capable of handling all kinds of failures. All services should be monitored
    for detecting failures and all failures should be handled. We have used the service
    discovery eureka for monitoring and Hystrix for circuit breaker pattern implementation
    in the last chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Elastic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A reactive system is elastic if it reacts to the load by utilizing the hardware
    and other resources optimally. It can bring up new instances of a microservice
    or microservices if the demand increases and vice versa. On special sales days,
    such as Black Friday, Christmas, Diwali, and so on, a reactive shopping application
    would instantiate a greater number of microservice nodes in order to share the
    load of increased requests. On normal days, the shopping application may not require
    a bigger number of resources than on average, hence it can reduce the number of
    nodes. Therefore, for effectively using the hardware, a reactive system should
    be elastic in nature.
  prefs: []
  type: TYPE_NORMAL
- en: Message driven
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A reactive system would sit idle if it has nothing to do; it would not use the
    resources unnecessarily if it was not supposed to do anything. An event or a message
    may make a reactive microservice active and then start working (reacting) on the
    received event/message (request). Ideally, communication should be asynchronous
    and non-blocking by nature. A reactive system uses messages for communication—asynchronous
    message passing. In this chapter, we'll use the Apache Kafka for messaging.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, a reactive programming language is the best way to implement the reactive
    microservices. A reactive programming language provides asynchronous and non-blocking
    calls. Java could also be used for developing the reactive microservices with
    the use of Java streaming feature. Kafka would be used for messaging with Kafka's
    Java libraries and plugins. We have already implemented service discovery and
    registry service (Eureka Server-monitoring), the proxy server (Zuul) with Eureka
    for elasticity, and Hystrix with Eureka for Circuit Breaker (resilient and responsive).
    In the next section, we will implement the message-driven microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing reactive microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reactive microservice performs operations in response to events. We'll make
    changes in our code to produce and consume events for our sample implementation.
    Although we'll create a single event, a microservice can have multiple producers
    or consumer events. Also, a microservice can have both producer and consumer events.
    We'll make use of the existing functionality in the Booking microservice that
    creates the new booking (`POST /v1/booking`). This will be our event source and
    would make use of Apache Kafka for sending this event. Other microservices can
    consume this event by listening to the event. On successful booking call, the
    Booking microservice will produce the Kafka topic (event) `amp.bookingOrdered`.
    We'll create a new microservice Billing (in the same way in which we created the
    other microservices like Booking) for consuming this event (`amp.bookingOrdered`).
  prefs: []
  type: TYPE_NORMAL
- en: Producing an event
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An object would be sent to Kafka once an event is produced. Similarly, Kafka
    would send this produced object to all listeners (microservices). In short, the
    produced object travels over the network. Therefore, we need serialization support
    for these objects. We'll make use of Apache Avro for data serialization. It defines
    the data structure (schema) in the JSON format and also provides a plugin for
    both Maven and Gradle to generate Java classes using JSON schema. Avro works well
    with Kafka because both Avro and Kafka are Apache products and align well with
    each other for integration.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with defining the schema that represents the object sent over the
    network when a new booking is created. As shared earlier for producing the event,
    we'll make use of the existing Booking microservice. We'll create the Avro schema
    file `bookingOrder.avro` in `src/main/resources/avro` directory in Booking microservice.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `bookingOrder.avro` file will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, `namespace` represents the package `type` which is `record` represents
    the class, `name` represents the name of the class, and `fields` represent the
    properties of the class. When we generate the Java class using this schema, it
    would create the new Java class `BookingOrder.java` in the `com.packtpub.mmj.booking.domain.valueobject.avro
    package`, with all properties defined in `fields`.
  prefs: []
  type: TYPE_NORMAL
- en: In `fields` too, we have `name` and `type` that represent the name and type
    of the property. For all fields, we have used the input `type` as `string`. You
    could also use other primitive types such as `boolean`, `int`, and `double`. Also,
    you can use complex types such as `record` (used in the preceding code snippet),
    `enum`, `array`, and `map`. The `default` type represents the default value of
    the property.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding schema would be used to generate the Java code. We''ll make use
    of the `avro-maven-plugin` to generate the Java source files from the preceding
    Avro schema. We''ll add this plugin in the plugins section of the child `pom`
    files (service''s `pom.xml`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can see that in the `configuration` section, `sourceDirectory` and `outputDirectory`
    are configured. Therefore, when we run `mvn package`, it would create the `BookingOrder.java`
    file in the `com.packtpub.mmj.booking.domain.valueobject.avro` package located
    inside the configured `outputDirectory`.
  prefs: []
  type: TYPE_NORMAL
- en: Now that our Avro schema and the generated Java source is available to us, we'll
    add Maven dependencies that are required for producing the event.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding dependency in the Booking microservice `pom.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have added the three main dependencies: `avro`, `spring-cloud-stream`,
    and `kafka-clients`. Also, we have added stream integration with Kafka (`spring-cloud-starter-stream-kafka`)
    and stream support schema (`spring-cloud-stream-schema`).'
  prefs: []
  type: TYPE_NORMAL
- en: Now, since our dependencies are in place, we can start writing producer implementation.
    Booking microservice would send the `amp.bookingOrdered` event to the Kafka stream.
    We'll declare the message channel for this purpose. It can be done either using
    `Source.OUTPUT` with the `@InboundChannelAdapter` annotation or by declaring the
    Java interface. We'll use the interface approach because it is easier to understand
    and correlate.
  prefs: []
  type: TYPE_NORMAL
- en: We'll create the `BookingMessageChannels.java` message channel in the `com.packtpub.mmj.booking.domain.service.message`
    package. Here, we can add all the message channels that are required. Since we
    are using the single event for sample implementation, we have to just declare
    the `bookingOrderOutput`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `BookingMessageChannels.java` file will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have just defined the name of the message channel, `bookingOrderOutput`,
    using the `@Output annotation`. We also need to configure this message channel
    in `application.yaml`. We''ll use this name to define the Kafka topic in the `application.yaml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, the Kafka topic name `amp.bookingOrdered` is given that is bound to the
    `bookingOrderOutput` message channel. (Kafka topic name could be any string. We
    prefix `amp` to denote asynchronous message passing; you can use Kafka topic name
    with or without prefix.)
  prefs: []
  type: TYPE_NORMAL
- en: We also need a message converter that would send the `BookingOrder` object to
    Kafka. For this purpose, we'll create an `@Bean` annotation that would return
    the Spring `MessageConverter` in the Booking service main class.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `@Bean` annotation in `BookingApp.class` file will look something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You may add more beans based on required schemas for respective schemas. We
    have not yet configured the Kafka server in `application.yaml`, which is set to
    `localhost`. Let's do it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configuring the Kafka server in the `application.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have configured `localhost` for both `zkNodes` and `brokers`; you can
    change it to the host where Kafka is hosted.
  prefs: []
  type: TYPE_NORMAL
- en: We are ready for sending the `amp.bookingOrdered` Kafka topic to the Kafka server.
    For simplicity, we'll directly add a `produceBookingOrderEvent` method that takes
    the `Booking` class as a parameter in the `BookingServiceImpl.java` class (you
    need to add the same method signature in `BookingService.java`). Let's see the
    code first.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `BookingServiceImpl.java` file is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have declared the `bookingMessageChannel` object that is autowired
    using the `setter` method. The Spring cloud stream annotation `@EnableBinding`
    binds the `bookingOrderOutput` message channel declared in the `BookingMessageChannels`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: The `produceBookingOrderEvent` method is added, which takes the `booking` object.
    Inside the `produceBookingOrderEvent` method, the `BookingOrder` object properties
    are set using the `booking` object. Then the message is built using the `bookingOrder`
    object. At the end, the message is sent to Kafka using `bookingMessageChannels`.
  prefs: []
  type: TYPE_NORMAL
- en: The `produceBookingOrderEvent` method is called after the booking is successfully
    persisted in DB.
  prefs: []
  type: TYPE_NORMAL
- en: 'To test this functionality, you can run the Booking microservice with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Ensure that the Kafka and Zookeeper applications are running properly on hosts
    and ports defined in the `application.yaml` file for performing successful testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, fire a post request (`http://<host>:<port>/v1/booking`) for a booking
    through any REST client with the following payload:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'It would produce the `amp.bookingOrdered` Kafka topic (event) as shown in following
    logs published on the Booking microservice console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the Kafka console would display the following message that confirms
    that the message is received successfully by Kafka:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can now move to code the consumer of the previously generated event.
  prefs: []
  type: TYPE_NORMAL
- en: Consuming the event
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we'll add the new module `billing-service` in the parent `pom.xml` file
    and create the Billing microservice the way other microservices are created in
    [Chapter 5](b1f93b4e-3475-4d8a-8c9f-697b0fd4410c.xhtml), *Deployment and Testing*.
    Most of the reactive code we have written for the Booking microservice will be
    reused for a Billing microservice, such as Avro schema and `pom.xml` entries.
  prefs: []
  type: TYPE_NORMAL
- en: We'll add the Avro schema in Billing microservice in same way we have added
    it in Booking microservice. Since schema namespace (package name) would be the
    same `booking` package in Billing microservice, we need to add value `com.packtpub.mmj.booking`
    in the `scanBasePackages` property of `@SpringBootApplication` annotation in `BillingApp.java`.
    It would allow the spring context to scan booking package also.
  prefs: []
  type: TYPE_NORMAL
- en: We'll add following dependencies in the Billing microservice `pom.xml`, which
    is the same as we have added in Booking microservice.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pom.xml` file for Billing microservice is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: You can refer to the booking service dependency paragraph for the reason behind
    the addition of these dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we''ll add the message channel in the Billing microservice, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are adding the input message channel opposite to the message channel
    in the booking service where we have added the output message channel. Note that
    `bookingOrderInput` is an input message channel marked with the `@input` annotation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we want to configure the `bookingOrderInput` channel to the Kafka topic
    `amp.BookingOrdered`. We''ll modify the `application.yaml` for this purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the Kafka topic is added to the `bookingOrderInput` channel using the
    destination property. We''ll also configure Kafka in the Billing microservice
    (`application.yaml`) the way we have configured it in the Booking microservice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now, we'll add the event listener that would listen to the stream bound to the
    `bookingOrderInput` message channel using the `@StreamListener` annotation available
    in the Spring Cloud Steam library.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `EventListener.java` file is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Here, you can also add other event listeners. For example, we'll simply log
    the received object. You may add an additional functionality based on the requirement;
    you can even produce a new event again for further processing if required. For
    example, you can produce the event to a restaurant for which a new booking is
    requested, and so on, through a service that manages restaurant communication.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can enable the binding of the `bookingOrderInput` message channel
    to stream using the `@EnableBinding` annotation of the Spring Cloud Stream library
    and create the bean of the `EventListener` class created in `BillingApp.java`
    (the main class of the `billing-service` module) as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `BillingApp.java` will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can start the Billing microservice and raise a new `POST/v1/booking`
    REST call. You can find the received object in the Billing microservice log, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following links will give you more information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Apache Kafka**: [https://kafka.apache.org/](https://kafka.apache.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache Avro**: [https://avro.apache.org/](https://avro.apache.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Avro Specs**: [https://avro.apache.org/docs/current/spec.html](https://avro.apache.org/docs/current/spec.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spring Cloud Stream**: [https://cloud.spring.io/spring-cloud-stream/](https://cloud.spring.io/spring-cloud-stream/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about reactive microservices or event-based microservices.
    These services work on messages/events rather than REST calls over HTTP. They
    provide asynchronous communication among services, which provide non-blocking
    communication and allow better usage of resources and failure handling.
  prefs: []
  type: TYPE_NORMAL
- en: We have made use of Apache Avro and Apache Kafka with Spring Cloud Stream libraries
    for implementing the reactive microservices. We have added the code in the existing
    `booking-service` module for producing the `amp.bookingOrdered` messages under
    the Kafka topic and added new module `billing-service` for consuming the same
    event.
  prefs: []
  type: TYPE_NORMAL
- en: You may want to add a new event for producers and consumers. You can add multiple
    consumers for an event or create a chain of events as exercise.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn to secure the microservices with respect
    to authentication and authorization. We will also explore the other aspects of
    microservice securities.
  prefs: []
  type: TYPE_NORMAL
