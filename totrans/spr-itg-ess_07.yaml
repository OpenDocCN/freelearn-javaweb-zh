- en: Chapter 7. Integration with Spring Batch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today, a common user deals with web applications, mobile applications, and desktop
    software. All of these are interactive, which means they take user input and respond
    in real time. They might not even be aware of other kinds of applications—applications
    that run in the background, do not need continuous user interaction, and may go
    on for hours, days, or even weeks! Yes, I am talking about the batch job that
    is typically used for offline processing such as file type conversions, reporting,
    data mining, and so on. In the early days, machines were too slow and someone
    had to sit for hours to get a simple job done. In batch processing, you submit
    jobs and then go and do other work—you only come to collect the result! This revolutionized
    the computing world and justified the exorbitantly high prices of equipment and
    programmers. It would not be an exaggeration to say that batch jobs showed the
    real power and usefulness of computers.
  prefs: []
  type: TYPE_NORMAL
- en: 'If batch jobs are so important, it''s obvious that Spring would have a very
    good support for it. Spring Batch is the module that provides comprehensive support
    for batch processing. In this chapter, we will look into how Spring Integration
    integrates with the Spring Batch module. In sync with the Spring philosophy of
    modular approach, each module works independently and at the same time provides
    the necessary interfaces to be easily integrated with others in the family. Spring
    Integration can interact with the Spring Batch module via messaging and can provide
    an event-driven mechanism to trigger batch jobs. This chapter will cover two aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: A brief introduction to Spring Batch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Integration and Spring Batch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Batch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For a layman, a batch job can be defined as any job that can be run offline.
    Typically, it will be a manual trigger and the result can be collected after the
    expected completion time. If all goes well, then it''s really cool, but let''s
    list some of the challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: What if the external system that is used for a batch job (say an FTP server
    that hosts files) fails?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the machine running a batch job is rebooted for some reason, will the batch
    job also restart?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if some explicit parameters are required (for example, authentication details
    that might not be eligible for automation)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will incomplete tasks be tried again or left out?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we deal with transaction and rollback?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we trigger and schedule the job at fixed intervals or in an event-driven
    fashion?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the jobs run in a thread, who will manage resource synchronization?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we deal with the failures? Can the batch job trigger some alarm or send
    out notifications?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a lot of things that need to be accounted for—just imagine the difficulty
    if each of them has to be implemented by the programmer! Do not worry; Spring
    Batch is there to help you. With the help of Spring Integration, even the initial
    triggering part can be programmed—manual interaction is not required at all.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, Spring Batch is not a scheduling framework like Quartz, Tivoli,
    and others—rather, it leverages these frameworks. It is a very lightweight framework
    that provides reusable components to address most of the concerns raised previously,
    for example, transaction support, database support for recoverable jobs, logging,
    auditing, and so on. Let's start with the configuration step and then we can move
    up to the examples.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we can use the Spring Batch module, we need to add namespace support
    and Maven dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Namespace support**: Namespace support can be added by using the following
    code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Maven entry**: Maven entry support can be added by using the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Defining a Spring Batch job
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The unit of work in a Spring Batch is a *job*, which encapsulates all other
    aspects needed to complete a batch operation. Before we get into the details of
    how to configure and use Spring Batch components, let's familiarize ourselves
    with the basic terms used in a Spring Batch job.
  prefs: []
  type: TYPE_NORMAL
- en: The Spring Batch job language
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s familiarize ourselves with the basic domain language of Spring Batch,
    which will help us understand the example:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Job`: This represents a batch process, and it has one-to-one mapping. For
    each batch process, there will be one job. It can be defined either in XML or
    the Java configuration—I have used the XML approach.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Step`: This is the logical breakdown of a job—a job has one or more steps.
    It encapsulates the phases of a job. A step is the logical unit that contains
    the actual details for running and controlling the batch job. Each job step can
    specify its fault tolerance—for example, skip an item on error, halt the job,
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`JobInstance`: This is one instance of a job. For example, a job must be run
    once a day, and each day run will be represented by a `JobInstance`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`JobParameter`: This is the parameter that is necessary for a `JobInstance`
    to complete.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`JobExcecution`: When a `JobInstance` of a job is triggered, it may complete
    or fail. Each trigger of `JobInstance` is wrapped as `JobExecution`. So, for example,
    if a retry has been set and `JobInstance` is triggered thrice (due to failures)
    before it completes, then there are three instances of `JobExecution`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`StepExecution`: Similar to `JobExecution`, `StepExecution` is an instance
    of a single attempt to run a step. If a step completes after *n* retries, there
    will be *n* instances of `StepExecution`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ExecutionContext`: One of the important aspects of the batch job is the ability
    to restart and reschedule failed jobs; for that, it''s necessary to store enough
    information so that it can be triggered back, similar to a process context at
    the operating systemlevel. `ExecutionContext` is used to address this use case,
    which provides storage of key/value pairs of context-related properties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`JobRepository`: This is the persistence wrapper for all the aforementioned
    units. The underlying database provider can be from one of the many supported
    by Spring Batch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`JobLauncher`: This is an interface that is used to launch a job.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ItemReader`: This is an interface used by the step to read input. If the input
    set has been exhausted, `ItemReader` should indicate this by returning null.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ItemWriter`: This is the output interface of a step—one batch or chunk of
    items at a time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ItemProcessor`: This is the intermediate state of `ItemReader` and `ItemWriter`.
    It provides the opportunity to apply transformation or business logic to an item.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With the preceding introduction, we can understand the Spring Batch example
    a little bit better. So let''s start with one and define a batch job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the brief description of the tags used in the preceding configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '`batch:job`: This is the parent tag that starts the definition of the batch
    job. `id` is used to uniquely identify this job, for example, to refer inside
    a `JobLauncher` to launch this job.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch:step`: This is one of the steps for this job.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch:tasklet`: This is the implementation that does the actual task of the
    step, leaving the step to take care of status maintenance, eventing, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch:chunk`: A `tasklet` can be a simple service or a very complex task,
    while a `chunk` is a logical unit of work that can be worked upon by a `tasklet`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch:listeners`: These are used to propagate the events. We will revisit
    this later in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the reader and writer? As the name suggests, reader reads the chunk
    of data while writer writes them back. There are standard readers provided by
    Spring to read a CSV file, but we can provide our own implementation. Let's look
    at a reader and writer used for this example.
  prefs: []
  type: TYPE_NORMAL
- en: ItemReader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The components used in the preceding code snippet are explained in the following
    bullet points:'
  prefs: []
  type: TYPE_NORMAL
- en: '`itemReader`: This uses Spring''s default flat file reader, whose location
    has been mentioned by the `resource` property. The name will be retrieved from
    the `JobParameter` item passed to the job. We will see how to pass it when we
    write the launcher.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lineMapper`: This is a default implementation from Spring that has been used
    to map a line from the CSV file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lineTokenizer`: It is very important how each token on a line should be interpreted.
    The value of the property `names` decides the order. For example, in the preceding
    example, it is `name,designation,dept,address`, which means if a sample file has
    an entry like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Then each chunk will be interpreted as name, designation, department, and address,
    respectively.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`fieldSetMapper`: Although some default implementations are available, most
    of the time it is a custom class that defines the mapping between the item in
    a CSV file and the domain model. The following is the code snippet of our example
    that uses the mapper:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ItemWriter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A writer is used to write chunks of data. A writer is almost always user defined.
    It can be defined to write in a file, database, or JMS, or to any endpoint—it
    depends on our implementation. Towards the end of the chapter, we will discuss
    how this can be used to even trigger an event in the Spring Integration environment.
    Let''s first look at a simple writer configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code snippet is the implementation of the writer class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For simplicity, I have printed the records, but as mentioned previously, it
    can be populated in the database or it can be used to do whatever we want to do
    inside this class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, so far we have defined the job, the reader, and the writer; then what''s
    stopping us from launching it? How do we launch this batch job? Spring provides
    the `Joblauncher` interface that can be used to launch the job. `Joblauncher`
    needs an interface of the type `JobRepository` to store the context of the job
    so that it can be recovered and restarted on failure. `JobRepository` can be configured
    to leverage any database that Spring can use, for example, in-memory, MySql, PostGres,
    and so on. Let''s define `jobLauncher` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Since `JobLauncher` cannot be used without a `JobRepository`, let''s configure
    `JobRepository`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The properties shown in the preceding code can be configured in a `properties`
    file, let''s say `batch.properties`. We can provide the properties in a class
    path and use the `property-placeholder` tag to inject the properties, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'As soon as the database is there, we need transactions! Let''s configure the
    transaction manager:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Thank god, no more configurations! By the way, these are not specific to any
    batch job; any data source and transaction manager configured in the existing
    application can be used. With all these configurations, we are ready to launch
    the batch job. Let''s see the following sample code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s understand the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load the file**: We first load the configuration file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extract the reference**: The next step is to retrieve the reference of the
    defined job using its unique ID.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Add parameters**: A job needs a parameter, so we define `JobParameter` using
    the `JobParameterBuilder` class. The name of the file being passed as a value
    of the key is `input.file.name`, which was configured in the job definition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Launch the job**: Finally, use Spring''s `JobLauncher` class to launch the
    job.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hmm! Now we have a small and simple batch up and running. Let's see how Spring
    Integration can be used to reap its power and enhance the usage even further.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Batch and Spring Integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Typically, a batch application can be triggered via a command-line interface
    or programmatically, for example, from a web container. Let''s introduce Spring
    Integration and see the possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: It can be triggered on an event, for example, a file adapter listening for a
    file triggers Spring Integration on arrival of the file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execution can be chained in a flow—trigger the job, pass on the result, invoke
    the error path, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The message queue is not meant for huge amounts of data. So for big files, Spring
    Integration can act as the trigger, while delegating the actual task to Spring
    Batch. It can provide a strategy to chunk the files and distribute them across
    the Spring Batch job.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Integration not only triggers batch jobs, but can also collect the result
    and propagate it in the system. For example, a batch process triggered by Spring
    Integration may finish off in a day, after which `ItemWriter` can write an item
    to JMS on which the Spring Integration adapter is listening. Even without any
    awareness or locking in for the job started, messages from the queue will be processed
    by Spring Integration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launching the job
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Enough theory! Let''s write some code. This time, we will trigger the batch
    job on some event instead of triggering manually. We are processing a file, what
    if we process a file adapter? Let''s write a file adapter that will listen for
    files in a directory and trigger a batch job on the availability of a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: No need to define the file adapter tags, as they have been taken care of in
    the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding configuration will listen for files in the configured directory.
    Files will be put on to `fileOutPutChannel` as `Message<File>`, and we need to
    convert it to a form so that `JobLauncher` can understand it. We will use the
    `transformer` component:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We will have to write the logic to convert `Message<File>` to `JobLaunchRequest`.
    The following code is a very simple transformer that extracts the file path from
    the payload of `Message` (which is `File`) and then adds the retrieved path as
    `JobParameter`. This job parameter is then used to launch the job using Spring''s
    `JobLauncher`, as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: With this code in place, whenever a new file arrives in the directory, a batch
    job is triggered using Spring Integration. Moreover, file adapter was just an
    example, any adapter or gateway—such as mail, JMS, FTP, and others—can be plugged
    in to trigger the batch processing.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking the status of a batch job
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Most of the time, we would want to have feedback about the task in progress—how
    can we do that? Spring Integration is an event-based framework so no surprise
    that we can configure listeners with a batch job. If you refer to the batch job
    definition at the beginning, it has a listener defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This code can have a Spring Integration gateway as a listener, which listens
    for the notification and puts the status of the batch job (of the type `JobExecution`)
    on the defined channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The status will be available on a channel where we have our processing done.
    Let''s plug in a simple service activator to print the status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The other way round
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Spring Integration can launch the batch job, and Spring Batch can interact
    with the Spring Integration and trigger components. How can we do this? Spring
    Integration''s event-based components can be a good option. Let''s take a simple
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: There is an inbound JMS adapter in the Spring Integration application that listens
    for messages on the queue and, based on that, triggers some action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we invoke this adapter from Spring Batch? We can define a custom `ItemWriter`
    class in Spring Batch that writes its output to the JMS queue where the Spring
    Integration component is listening.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As soon as `ItemWriter` writes to the JMS queue, the inbound adapter picks it
    up and passes it down the line for further processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding use case is just one example; we can gel the eventing mechanism
    of both the frameworks and achieve the required inter-app communication.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This completes our discussion on how Spring Integration and Spring Batch can
    intercommunicate. We covered the basics of Spring Batch, how it can be leveraged
    by Spring Integration to delegate the processing of huge payloads, how status
    can be tracked, and then in turn how Spring Batch can trigger events and start
    processing in the Spring Integration application!
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss one of the most important aspects—testing.
    Keep up the energy!
  prefs: []
  type: TYPE_NORMAL
