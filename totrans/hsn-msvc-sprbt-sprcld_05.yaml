- en: Deploying Our Microservices Using Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will start using Docker and put our microservices into containers!
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, we will have run fully automated tests of our microservice
    landscape that start all our microservices as Docker containers, requiring no
    other infrastructure than a Docker engine. We will have also run a number of tests
    to verify that the microservices work together as expected and finally shut down
    all the microservices, leaving no traces of the tests we executed.
  prefs: []
  type: TYPE_NORMAL
- en: Being able to test a number of cooperating microservices in this way is very
    useful. As developers, we can verify that it works on our local developer machines.
    We can also run exactly the same tests in a build server to automatically verify
    that changes to the source code won't break the tests at a system level. Additionally,
    we don't need to have a dedicated infrastructure allocated to run these types
    of tests. In the upcoming chapters, we will see how we can add databases and queue
    managers to our test landscape, all of which will run as Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: This does not, however, replace the need for automated unit and integrations
    tests, which test individual microservices in isolation. They are as important
    as ever.
  prefs: []
  type: TYPE_NORMAL
- en: For production usage, as we mentioned earlier in this book, we need a container
    orchestrator such as Kubernetes. We will go back to container orchestrators and
    Kubernetes later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Docker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker and Java. Java hasn't been very friendly to containers historically,
    but that changed with Java 10\. Let's see how Docker and Java fit together on
    this topic!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Docker with one microservice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing a landscape of microservices using Docker Compose.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing them all together automatically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All of the commands that are described in this book are run on a MacBook Pro
    using macOS Mojave but should be straightforward to modify if you want to run
    them on another platform such as Linux or Windows.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the technical requirements from the previous chapter, we need to
    have Docker installed. Docker Community Edition can be downloaded from [https://store.docker.com/search?type=edition&offering=community](https://store.docker.com/search?type=edition&offering=community)[.](https://store.docker.com/search?type=edition&offering=community)
  prefs: []
  type: TYPE_NORMAL
- en: 'To be able to run the examples in this book, it is recommended that you configure
    Docker so that you can use all the CPUs except one (allocating all CPUs to Docker
    can make the computer unresponsive when tests are running) and at least 6 GB of
    memory. This can be configured in the Advanced tab in the Preferences settings
    for Docker, as illustrated by the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5fe1ee81-076f-4652-b550-bd63ba45cc3e.png)'
  prefs: []
  type: TYPE_IMG
- en: The source code for this chapter can be found in this book's GitHub repository: [https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter04](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter04).
  prefs: []
  type: TYPE_NORMAL
- en: 'To be able to run the commands that are described in this book, download the
    source code to a folder and set up an environment variable, `$BOOK_HOME`, that
    points to that folder. Some sample commands are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The Java source code is written for Java 8 and tested to run on Java 12\. This
    chapter uses Spring Boot 2.1.0 (and Spring 5.1.2), the latest available version
    of Spring Boot at the time of writing this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The code examples in this chapter all come from the source code in `$BOOK_HOME/Chapter04` but
    in many cases have been edited to remove irrelevant parts of the source code,
    such as comments, imports, and log statements.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to see the changes that were applied to the source code in this
    chapter, that is, see what it took to add support for Docker, you can compare
    it with the source code for [Chapter 3](d26f4e61-20bf-4f55-b96d-060c7dd6f20c.xhtml),
    *Creating a Set of Cooperating Microservices*. You can use your favorite `diff` tool
    and compare the two folders, `$BOOK_HOME/Chapter03/2-basic-rest-services` and `$BOOK_HOME/Chapter04`.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we already mentioned in [Chapter 2](7d969006-ea94-4bbb-858d-30dce8177a2c.xhtml),
    *Introduction to Spring Boot*, Docker made the concept of containers as a lightweight
    alternative to virtual machines very popular in 2013\. Containers are actually
    processed in a Linux host that uses Linux namespaces to provide isolation between
    containers of global system resources, such as users, processes, filesystems,
    and networking. **Linux Control Groups** (also knows as **cgroups**) are used
    to limit the amount of CPU and memory that a container is allowed to consume.
    Compared to a virtual machine that uses a hypervisor to run a complete copy of
    an operating system in each virtual machine, the overhead in a container is a
    fraction of the overhead in a virtual machine. This leads to much faster startup
    times and significantly lower overhead in terms of CPU and memory usage. The isolation
    that''s provided for a container, however, is not considered to be as secure as
    the isolation that''s provided for a virtual machine. With the release of Windows
    Server 2016 and Windows 10 Pro (1607 Anniversary Update), Microsoft supports the
    usage of Docker on Windows as well. Take a look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/caee1a35-71e9-4b6c-953f-b00a2d6eaca3.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram illustrates the difference between the resource usage
    of virtual machines and containers, visualizing that the same type of server can
    run significantly more containers than virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: Running our first Docker commands
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s try to start a container by launching an Ubuntu server in one using
    Docker''s `run` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: With the preceding command, we ask Docker to create a container that runs Ubuntu,
    based on the latest version that's available of the official Docker image for
    Ubuntu. The `-it` option is used so that we can interact with the container using
    Terminal, and the `--rm` option tells Docker to remove the container once we exit
    the Terminal session; otherwise, the container will remain in the Docker engine
    with an `Exited` state.
  prefs: []
  type: TYPE_NORMAL
- en: The first time we use a Docker image that we haven't built ourselves, Docker
    will download it from a Docker registry, which is Docker Hub by default ([https://hub.docker.com](https://hub.docker.com)).
    This will take some time, but for subsequent usage of that Docker image, the container
    will start in just a few seconds!
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the Docker image has been downloaded and the container has been started
    up, the Ubuntu server should respond with a prompt such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/39044aaf-927e-4210-9731-1a3f10fedd10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can try out the container by asking what version of Ubuntu it runs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'It should respond with something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/60a69639-0969-4d0f-ab2c-f8a2582d51eb.png)'
  prefs: []
  type: TYPE_IMG
- en: We can leave the container with an `exit` command and verify that the Ubuntu
    container no longer exits with the `docker ps -a` command. We need to use the `-a` option
    to see stopped containers; otherwise, only running containers are displayed.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you favor CentOS over Ubuntu, feel free to try the same with the `docker
    run --rm -it centos` command. Once the CoreOS server has started running in its
    container you can, for example, ask what version of CoreOS that it runs with the `cat
    /etc/redhat-release` command. It should respond with something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0bc608f2-03e6-40ec-a0b4-d343d9eff2b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Leave the container with the `exit` command to remove it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If, at some point, you find that you have a lot of unwanted containers in the
    Docker engine and you want to get a clean sheet, that is, get rid of them all,
    you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `docker rm -f` command stops and removes the containers whose container
    IDs are specified to the command. The `docker ps -aq` command lists the container
    IDs of all the running and stopped containers in the Docker engine. The `-q` option
    reduces the output from the `docker ps` command so that it only lists the container
    IDs.
  prefs: []
  type: TYPE_NORMAL
- en: After understanding what Docker is, next we can move on to understand the problems
    which we might face while running Java in Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges with running Java in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to Java, over the past few years, there have been a number of
    attempts to get Java working in Docker in a good way. Currently, the official
    Docker image for Java is based on OpenJDK: [https://hub.docker.com/_/openjdk/](https://hub.docker.com/_/openjdk/).
    We will use Java SE 12 with the Docker tag `openjdk:12.0.2`, that is, Java SE
    v12.0.2.
  prefs: []
  type: TYPE_NORMAL
- en: Java has historically not been very good at honoring the quotas specified for
    a Docker container using Linux cgroups; it has simply ignored these settings.
    So, instead of allocating memory inside the JVM in relation to the memory available
    in the container, Java allocated memory as if it had access to all the memory
    in the Docker host, which obviously isn't good! In the same way, Java allocated
    CPU-related resources such as thread pools in relation to the total number of
    available CPU cores in the Docker host instead of the number of CPU cores that
    were made available for the container JVM was running in. In Java SE 9, some initial
    support was provided, which was also back-ported to later versions of Java SE
    8\. In Java 10, however, much-improved support for CPU and memory constraints
    was put in place.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try it out!
  prefs: []
  type: TYPE_NORMAL
- en: First, we will try out Java commands locally, without Docker, since that tells
    us how much memory and the number of CPU cores that the JVM sees. Next, we will
    try the commands in Docker using Java SE 12 to verify that it honors the constraints
    we set on the Docker container it runs in. Finally, we will also try out a Java
    SE 9 container and see how it fails to honor the constraints and what problems
    it can result in.
  prefs: []
  type: TYPE_NORMAL
- en: Java without Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we jump in to Docker, let's try the Java commands without Docker to familiarize
    ourselves with the Java commands!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by finding out how many available processors, that is, CPU cores,
    Java sees when running outside of Docker. We can do this by sending the `Runtime.getRuntime().availableprocessors()` Java
    statement to the Java CLI tool `jshell`, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`jshell` requires Java SE 9 or later!'
  prefs: []
  type: TYPE_NORMAL
- en: 'On my machine, I get the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47ae0858-fb1f-43ec-988a-303e04880a4d.png)'
  prefs: []
  type: TYPE_IMG
- en: Okay, `12` cores is as expected, since the processor in my laptop is a six-core Intel
    Core i9 CPU with hyper-threading (the operating system sees two virtual cores
    for each physical core).
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of the amount of available memory, let''s ask the JVM for the maximum
    size that it thinks it can allocate for the heap. We can achieve this by asking
    the JVM for extra runtime information using the `-XX:+PrintFlagsFinal` Java option
    and then using the `grep` command to filter out the `MaxHeapSize` parameter, like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'On my machine, I get the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98ea076e-f964-4885-b262-e8020b7b702c.png)'
  prefs: []
  type: TYPE_IMG
- en: '`8589934592` bytes happens to be exactly 8 GB, that is, *8 * 1,024^3*. Given
    that we don''t specify any max heap size for the JVM using the `-Xmx` parameter,
    the JVM will set the max value to one quarter of the available memory. Since my laptop
    has 32 GB of memory and *32/4=8*, this is also as expected!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s wrap this up by verifying that we can lower the maximum heap size with the `-Xmx` parameter
    to, for example, 200 MB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The JVM will respond with *209,715,200* bytes, that is, *200 ** *1,024^3* bytes
    = 200 MB, as expected!
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen how the Java commands work without Docker, let's try this
    with Docker!
  prefs: []
  type: TYPE_NORMAL
- en: Java in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's look at how Java SE 12 responds to limits we set on a container it runs
    in!
  prefs: []
  type: TYPE_NORMAL
- en: Since I'm using Docker for macOS, I'm actually running the Docker engine on
    a virtual machine on my MacBook Pro as the Docker host. I have configured Docker
    for macOS so that it allows the Docker host to use all 12 cores in my macOS but
    only use up to 16 GB of memory. All in all, the Docker host has 12 cores and 16
    GB of memory.
  prefs: []
  type: TYPE_NORMAL
- en: CPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start by applying no constraints, that is, the same test that we did
    without Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This command will send the `Runtime.getRuntime().availableProcessors()` string
    to the Docker container that will process the string using `jshell`.
  prefs: []
  type: TYPE_NORMAL
- en: 'It will respond with the same result, that is, `$1 ==> 12` in my case. Let''s
    move on and restrict the Docker container to only be allowed to use three CPU
    cores using the `--cpus 3` Docker option and ask the JVM about how many available
    processors it sees:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The JVM now responds with `$1 ==> 3`, that is, Java SE 12 honors the settings
    in the container and will, therefore, be able to configure CPU-related resources
    such as thread pools correctly!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s also try to specify a relative share of the available CPUs instead of
    an exact number of CPUs. 1,024 shares correspond to one core by default, so if
    we want to limit the container to two cores, we set the `--cpu-shares` Docker
    option to 2,048, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The JVM will respond with `$1 ==> 2`, that is, Java SE 12 honors the relative
    `share` option as well!
  prefs: []
  type: TYPE_NORMAL
- en: While the `--cpus` option is a hard constraint, the `--cpu-shares` option only
    applies when the Docker host is under high load. This means that a container can
    consume more CPU than what the `share` option indicates whether CPU capacity is
    available.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try out limiting the amount of memory next.
  prefs: []
  type: TYPE_NORMAL
- en: Memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With no memory constraints, Docker will allocate one-fourth of the memory to
    the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It will respond with 4,202,692,608 bytes, which equals 4 GB, that is, *8 * 1024^3*.
    Since my Docker host has 16 GB of memory, this is correct, that is, *16/4 = 4*.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if we constrain the Docker container to only use up to 1 GB of memory
    using the `-m=1024M` Docker option, we will see a lower memory allocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The JVM will respond with 268,435,456 bytes, which equals 256 MB, that is, *2 *
    1024^2* bytes. 256 MB is one-fourth of 1 GB, so again, this is as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can, as usual, set the max heap size ourselves. For example, if we want
    to allow the heap to use 800 MB of the total 1 GB we have, we can specify that
    using the `-Xmx800m` Java option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The JVM will respond with 838,860,800 bytes = *800 * 1024^2* bytes = 800 MB,
    as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Let's conclude with some out of memory tests to ensure that this really works.
  prefs: []
  type: TYPE_NORMAL
- en: Let's allocate some memory using `jshell` in a JVM that runs in a container
    that has been given 1 GB of memory; that is, it has a max heap size of 256 MB.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, try to allocate a byte array of 100 MB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The command will respond with `$1 ==>`, meaning that it worked fine!
  prefs: []
  type: TYPE_NORMAL
- en: Normally, `jshell` will print out the value resulting from the command, but
    100 MB of bytes all set to zero is a bit too much printout, and so we get nothing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s try to allocate a byte array that is larger than the max heap size,
    for example, 500 MB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The JVM sees that it can''t perform the action since it honors the container
    settings of max memory and responds immediately with `Exception java.lang.OutOfMemoryError:
    Java heap space`. Great!'
  prefs: []
  type: TYPE_NORMAL
- en: What would happen in this case if we use a JVM that doesn't honor the container
    settings of max memory?
  prefs: []
  type: TYPE_NORMAL
- en: Let's find out by using Java SE 9!
  prefs: []
  type: TYPE_NORMAL
- en: Problems with Docker and Java SE 9 (or older)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, try out limiting a Java SE 9 JVM to three CPU cores using `openjdk:9-jdk` image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Java 9 fails to obey the three-CPU limit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It responds with `$1 ==> 12` on my machine, that is, it ignores the limitation
    of three CPU cores.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will see the same result, that is, `$1 ==> 12`, if we try out the `--cpu-shares`
    option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s try to limit the memory to 1 GB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As expected, Java SE 9 does not honor the memory constraint that we set in Docker;
    that is, it reports a max heap size of 4,202,692,608 bytes = *4 GB – 4 * 1024^3*
    bytes. Here, Java 9 calculated the available memory when given the memory in the
    Docker host, not in the actual container!
  prefs: []
  type: TYPE_NORMAL
- en: So, what happens if we repeat the memory allocation tests that we did for Java
    SE 12?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try out the first test, that is, allocating a 100 MB array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The command responds with `$1 ==> byte[100000000] { 0, 0, 0, ...`, so that worked
    fine!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s move on to the really interesting test: what if we allocate a byte
    array of 500 MB that doesn''t fit in the memory that was allocated to the container
    by Docker?'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: From a Java perspective, this should work. Since Java thinks the total memory
    is 16 GB, it has set the max heap size to 4 GB, so it happily starts to allocate
    500 MB for the byte array. But after a while, the total size of the JVM exceeds
    1 GB and Docker will kill the container with no mercy, resulting in a confusing
    exception such as `State engine terminated`. We basically have no clue what went
    wrong, even though we can guess that we ran out of memory.
  prefs: []
  type: TYPE_NORMAL
- en: So, to summarize, if you plan to do any serious work with Docker and Java, ensure
    that you use Java SE 10 or later!
  prefs: []
  type: TYPE_NORMAL
- en: To be fair to Java SE 9, it should be mentioned that Java SE 9 contains some
    initial support for cgroups. If you specify the Java options `-XX:+UnlockExperimentalVMOptions` and `-XX:+UseCGroupMemoryLimitForHeap`,
    it will honor parts of the cgroup constraints, but not all of them, and it should
    be noted that this is only experimental. Due to this, it should be avoided in
    production environments. Simply use Java SE 10 or later in Docker!
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker with one microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we understand how Java works, we can start using Docker with one of
    our microservices. Before we can run our microservice as a Docker container, we
    need to package it in a Docker image. To build a Docker image, we need a Dockerfile,
    so we will start with that. Next, we need a Docker-specific configuration for
    our microservice. Since a microservice that runs in a container is isolated from
    other microservices, for example, has its own IP address, hostname, and ports,
    it needs a different configuration compared to when it's running on the same host
    with other microservices. For example, since the other microservices no longer
    run on the same host, no port conflicts will occur. When running in Docker, we
    can use the default port `8080` for all our microservices without any risk of
    port conflicts. On the other hand, if we need to talk to the other microservices,
    we can no longer use localhost like we could when we ran them on the same host.
    The source code in the microservices will not be affected by running the microservices
    in containers, only their configuration.
  prefs: []
  type: TYPE_NORMAL
- en: To handle the different configurations that are required when running locally
    without Docker and when running the microservices as Docker containers, we will
    use Spring profiles. Since [Chapter 3](d26f4e61-20bf-4f55-b96d-060c7dd6f20c.xhtml), *Creating
    a Set of Cooperating Microservices*, we have been using the default Spring profile
    for running locally without Docker, so we will create a Spring profile named `docker`
    for when we run our microservices as containers in Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Changes in source code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use the `product` microservice, which can be found in the source code
    at `$BOOK_HOME/Chapter04/microservices/product-service/`. In the next section,
    we will apply this to the other microservices as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we add the Spring profile for Docker at the end of the property file
    `$BOOK_HOME/Chapter04/microservices/product-service/src/main/resources/application.yml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Spring profiles can be used to specify environment-specific configuration, which
    in this case is a configuration that is to only be used when running the microservice
    in a Docker container. Other examples are configurations that are specific to
    `dev`, `test`, and production environments. Values in a profile override the default
    values, that is, values from the default profile. Using `.yaml` files, multiple
    Spring profiles can be placed in the same file, separated by ``---``.
  prefs: []
  type: TYPE_NORMAL
- en: The only parameter we will change is the port that's being used; that is, we
    will use the default port `8080` when running the microservice in a container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will create the `Dockerfile` that we will use to build the Docker
    image, `$BOOK_HOME/Chapter04/microservices/product-service/Dockerfile`. It looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Some things to take note of are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We will base our Docker image on the official Docker image for OpenJDK and use
    the Java SE v12.0.2.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will expose port `8080` to other Docker containers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We add our `fat-jar` file to the Docker image from the Gradle build library, `build/libs`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will specify the command to be used by Docker when a container is started
    up using this Docker image, that is, `java -jar /app.jar`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After taking into account these changes in source code
  prefs: []
  type: TYPE_NORMAL
- en: Building a Docker image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To build the Docker image, we need to build our deployment artifact, that is,
    the fat-file, for `product-service`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Since we only want to build `product-service` and the projects it depends on,
    `api` and `util`, we don't use the normal `build` command, which builds all the
    microservices, but a variant that tells Gradle to only build `product-service`: `:microservices:product-service:build`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can find the `fat-jar` file in the Gradle build library, `build/libs`. For
    example, the `ls -l microservices/product-service/build/libs` command will report
    something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2af54aa7-9e16-41b1-964a-021bda81ebd5.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the JAR file is close to 20 MB in size – no wonder they are
    called `fat-jar` files!
  prefs: []
  type: TYPE_NORMAL
- en: If you are curious about its actual content, you can view it by using the `unzip
    -l microservices/product-service/build/libs/product-service-1.0.0-SNAPSHOT.jar`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will build the Docker image and name it `product-service`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Docker will use the Dockerfile in the current directory to build the Docker
    image. The image will be tagged with the name `product-service` and stored locally
    inside the Docker engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Verify that we got a Docker image, as expected, by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/81cd92d2-7f8a-42a7-8e75-bfd20c69a1a6.png)'
  prefs: []
  type: TYPE_IMG
- en: So now that we have built the image, lets see how we can start the service.
  prefs: []
  type: TYPE_NORMAL
- en: Starting up the service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start up the `product` microservice as a container by using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This is what we can infer from the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker run`: The Docker run command will start the container and display log
    output in Terminal. Terminal will be locked as long as the container runs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We have seen the `--rm` option already; it will tell Docker to clean up the
    container once we stop the execution from Terminal using *Ctrl + C*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `-p8080:8080` option maps port `8080` in the container to port `8080` in
    the Docker host, which makes it possible to call it from the outside. In the case
    of Docker for macOS, which runs Docker in a local Linux virtual machine, the port
    will also be port-forwarded to macOS, which is made available on localhost. We
    can only have one container mapping to a specific port in the Docker host!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With the `-e` option, we can specify environment variables for the container,
    which in this case is `SPRING_PROFILES_ACTIVE=docker`. The `SPRING_PROFILES_ACTIVE` environment
    variable is used to tell Spring what profile to use. In our case, we want Spring
    to use the `docker` profile.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we have `product-service`, which is the name of the Docker image that
    Docker will use to start the container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The expected output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6418f725-7182-4415-a87c-283962b36cad.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is what we infer from the preceding output:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The profile that''s used by Spring is `docker`. Look for `The following profiles
    are active: docker` in the output to verify this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The port that''s allocated by the container is `8080`. Look for `Netty started
    on port(s): 8080` in the output to verify this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The microservice is ready to accept requests once the log message `Started ProductServiceApplication` has
    been written!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Try out the following code in another Terminal window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Note that we can use port `8080` on localhost, as explained previously!
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the expected output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/da91fca5-5223-4ded-b277-26ef0ea17866.png)'
  prefs: []
  type: TYPE_IMG
- en: This is similar to the output we received from the previous chapter, but with
    one major difference; we have the content of `"service Address":"aebb42b32fef/172.17.0.2:8080"`,
    the port is `8080`, as expected, and the IP address, `172.17.0.2`, is an IP address
    that's been allocated to the container from an internal network in Docker – but
    where did the hostname, `aebb42b32fef`, come from?
  prefs: []
  type: TYPE_NORMAL
- en: 'Ask Docker for all the running containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We will see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab9eb9ee-8dc6-4e0c-bcd2-14269175f84c.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see from the preceding output that, the hostname is equivalent to
    the ID of the container, which is good to know if you want to understand what
    container actually responded to your request!
  prefs: []
  type: TYPE_NORMAL
- en: Wrap this up by stopping the container in Terminal with the *Ctrl + C* command.
    With this done, we can now move on to running the container detached while being
    detached.
  prefs: []
  type: TYPE_NORMAL
- en: Running the container detached
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Okay, that was great, but what if we don't want to hang the Terminal windows
    from where we started the container?
  prefs: []
  type: TYPE_NORMAL
- en: It's time to start the container as detached, that is, running the container
    without locking Terminal!
  prefs: []
  type: TYPE_NORMAL
- en: 'We can do this by adding the `-d` option and at the same time giving it a name
    using the `--name` option. The `--rm` option is no longer required since we will
    stop and remove the container explicitly when we are done with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the `docker ps` command again, we will see our new container, called `my-prd-srv`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a683c0b3-0d98-4e01-afad-b521ee76cd42.png)'
  prefs: []
  type: TYPE_IMG
- en: But how do we get the log output from our container?
  prefs: []
  type: TYPE_NORMAL
- en: 'Meet the Docker `logs` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The `-f` option tells the command to follow the log output, that is, not end
    the command when all the current log output has been written to Terminal, but
    also wait for more output. If you expect a lot of old log messages that you don't
    want to see, you can also add the `--tail 0` option so that you only see new log
    messages. Alternatively, you can use the `--since` option and use either an absolute
    timestamp or a relative time, for example, `--since 5m`, to see log messages that
    are at most five minutes old.
  prefs: []
  type: TYPE_NORMAL
- en: Try this out with a new `curl` request. You should see that a new log message
    has been written to the log output in Terminal!
  prefs: []
  type: TYPE_NORMAL
- en: 'Wrap this up by stopping and removing the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The `-f` option forces Docker to remove the container, even if it is running.
    Docker will automatically stop the container before it removes it.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to use Docker with a microservice, we can now see how to
    manage a microservices landscape with the help of Docker Compose and see the changes
    in it.
  prefs: []
  type: TYPE_NORMAL
- en: Managing a landscape of microservices using Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've already seen how we can run a single microservice as a Docker container,
    but what about managing a whole system landscape of microservices?
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned earlier, this is the purpose of `docker-compose`. By using single
    commands, we can build, start, log, and stop a group of cooperating microservices
    running as Docker containers!
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the source code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be able to use Docker Compose, we need to create a configuration file, `docker-compose.yml`,
    that describes the microservices Docker Compose will manage for us. We also need
    to set up Dockerfiles for the remaining microservices and add a Docker-specific
    Spring profile to each of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'All four microservices have their own Dockerfile, but they all look the same
    as the preceding one. You can find them here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`$BOOK_HOME/Chapter04/microservices/product-service/Dockerfile`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`$BOOK_HOME/Chapter04/microservices/recommendation-service/Dockerfile`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`$BOOK_HOME/Chapter04/microservices/review-service/Dockerfile`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`$BOOK_HOME/Chapter04/microservices/product-composite-service/Dockerfile`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When it comes to the Spring profiles, the three core services, `product`, `recommendation`,
    and `review-service`, have the same `docker` profile, which only specifies that
    the default port `8080` should be used when running as a container.
  prefs: []
  type: TYPE_NORMAL
- en: 'For `product-composite-service`, things are a bit more complicated since it
    needs to know where to find the core services. When we ran all the services on
    localhost, it was configured to use localhost and individual port numbers, `7001`-`7003`,
    for each core service. When running in Docker, each service will have its own
    hostname but will be accessible on the same port number, `8080`. Here, the `docker`
    profile for `product-composite-service` looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: See `$BOOK_HOME/Chapter04/microservices/product-composite-service/src/main/resources/application.yml` for
    details.
  prefs: []
  type: TYPE_NORMAL
- en: Where did the hostnames, products, recommendations, and reviews come from?
  prefs: []
  type: TYPE_NORMAL
- en: 'These are specified in the `docker-compose.yml` file, which is located in the
    `$BOOK_HOME/Chapter04` folder. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'For each microservice, we specify the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The name of the microservice. This will also be the hostname of the container
    in the internal Docker network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A build directive that specifies where to find the Dockerfile that was used
    to build the Docker image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A memory limit of 350 MB. This ensures that all containers in this and the upcoming
    chapters will fit in the 6 GB of memory that we allocated to the Docker engine
    in the *Technical requirements* section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The environment variables that will be set up for the container. In our case,
    we used these to specify what Spring profile to use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the `product-composite` service, we will also specify port mappings, that
    is, we will expose its port to the outside of Docker. The other microservices
    will not be accessible from the outside. Next, we will see how to start up a microservice
    landscape.
  prefs: []
  type: TYPE_NORMAL
- en: Starting up the microservice landscape
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With all the necessary code changes in place, we can build our Docker images,
    start up the microservice landscape, and run some tests to verify that it works
    as expected. For this, we need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we build our deployment artifacts with Gradle and then the Docker images
    with Docker Compose:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to verify that we can see our Docker images, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We should see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/75213781-b3ea-4f66-84b9-62727717d4c5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Start up the microservices landscape with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The `-d` option means the same as for Docker, as described previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can follow the startup by monitoring the output that''s written to each
    container log with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The `docker compose logs` command supports the same `-f` and `--tail` options
    as `docker logs`, as described earlier.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker Compose `logs` command also supports restricting the log output to
    a group of containers. Simply add the names of the containers you want to see
    the log output of after the `logs` command. For example, to only see log output
    from the `product` and `review` service, use `docker-compose logs -f product review`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When all four microservices have reported that they have started up, we are
    ready to try out the microservices landscape. Look for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/760e3b57-8782-48c5-90ef-7ec483ef7f0e.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that each log message is prefixed with the name of the container that produces
    the output!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are ready to run some tests to verify that this works as expected. The
    only change we need to make when calling the composite service in Docker from
    when we ran it directly on the localhost, as we did in the previous chapter, is
    the port number. We now use port `8080`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We will get the same type of response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ea65b614-de1e-426a-83dc-b750d6cef6be.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, there''s one big difference – the hostnames and ports reported by
    `serviceAddresses` in the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/60a1a060-0f7d-4bb9-9088-89a1c926ae2b.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we can see the hostnames and IP addresses that have been allocated to
    each of the Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re done; now only one step is left:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command will shut down the microservices landscape.
  prefs: []
  type: TYPE_NORMAL
- en: Testing them all together automatically
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Compose is really helpful when it comes to manually managing a group
    of microservices! In this section, we will take this one step further and integrate
    Docker Compose into our test script, `test-em-all.bash`. The test script will
    automatically start up the microservice landscape, run all the required tests
    to verify that the microservice landscape works as expected, and finally tear
    it down, leaving no traces behind.
  prefs: []
  type: TYPE_NORMAL
- en: The test script can be found at `$BOOK_HOME/Chapter04/test-em-all.bash`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before the test script runs the test suite, it will check for the presence
    of a `start` argument in the invocation of the test script. If found, it will
    restart the containers with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, the test script will wait for the `product-composite` service to
    respond with OK:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The `waitForService` bash function can be implemented like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, all the tests are executed like they were previously. Afterward, they
    will tear down the landscape if it finds the `stop` argument in the invocation
    of the test scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Note that the test script will not tear down the landscape if some tests fail;
    it will simply stop, leaving the landscape up for error analysis!
  prefs: []
  type: TYPE_NORMAL
- en: The test script has also changed the default port from `7000`, which we used
    when we ran the microservices without Docker, to `8080`, which is used by our
    Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try it out! To start the landscape, run the tests and tear it down afterward,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is some sample output from a test run (with output from the specific
    tests that were deleted):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/16df5488-1e1d-45e3-850e-fad5f66cdbaf.png)'
  prefs: []
  type: TYPE_IMG
- en: After testing these, we can now move on to see how to troubleshoot tests that
    fail.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting a test run
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If the tests that were running `./test-em-all.bash start stop` fail, following
    these steps can help you identify the problem and resume the tests once the problem
    has been fixed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, check the status of the running microservices with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'If all the microservices are up and running and healthy, you will receive the
    following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8cdb0618-6760-4126-a3f5-abb60989b739.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If any of the microservices do not have a status of `Up`, check its log output
    for any errors by using the `docker-compose logs` command. For example, you would
    use the following code if you wanted to check the log output for the `product`
    service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'If errors in the log output indicate that Docker is running out of disk space,
    parts of it can be reclaimed with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'If required, you can restart a failed microservice with the `docker-compose
    up -d --scale` command. For example, you would use the following code if you wanted
    to restart the `product` service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'If a microservice is missing, for example, due to a crash, you start it up
    with the `docker-compose up -d --scale` command. For example, you would use the
    following code for the `product` service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Once all the microservices are up and running and healthy, run the test script
    again, but without starting the microservices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The tests should run fine!
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, a tip about a combined command that builds runtime artifacts and Docker
    images from source and then runs all the tests in Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '`./gradlew clean build && docker-compose build && ./test-em-all.bash start
    stop`'
  prefs: []
  type: TYPE_NORMAL
- en: This is perfect if you want to check that everything works before you push new
    code to your Git repository or as part of a build pipeline in your build server!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how Docker can be used to simplify testing a landscape
    of cooperating microservices.
  prefs: []
  type: TYPE_NORMAL
- en: We learned how Java SE since v10 honors constraints that we put on containers
    regarding how much CPU and memory they are allowed to use.
  prefs: []
  type: TYPE_NORMAL
- en: We have also seen how little it takes to make it possible to run a Java-based
    microservice as a Docker container. Thanks to Spring profiles, we can run the
    microservice in Docker without having to make any code changes.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we have seen how Docker Compose can help us manage a landscape of cooperating
    microservices with single commands, either manually or, even better, automatically,
    when integrated with a test script such as `test-em-all.bash`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will study how we can add a documentation of the API
    using OpenAPI/Swagger descriptions.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the major differences between a virtual machine and a Docker container?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of namespaces and cgroups in Docker?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What happens with a Java application that doesn't honor the max memory settings
    in a container and allocates more memory than it is allowed to?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we make a Spring-based application run as a Docker container without
    requiring modifications of its source code?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why will the following Docker Compose code snippet not work?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
